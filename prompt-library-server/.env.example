# Prompt Library Server Environment Configuration

# GLM-4.7 Coding API Key (Required for workflow generation)
# Get your API key from: https://api.z.ai/
# The backend proxy uses this key to make secure API calls without exposing it to clients.
GLM_CODING_API_KEY=your_glm_coding_api_key_here

# Server Configuration
PORT=3000
ENABLE_HTTP=true

# CORS Configuration (comma-separated origins)
# Allowed origins for API access
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# Rate Limiting
# General API rate limit (requests per minute per IP)
RATE_LIMIT_GENERAL=100

# GLM API rate limit (requests per minute per IP)
# Separate limit to prevent GLM API abuse
RATE_LIMIT_GLM=20

# Node Environment
NODE_ENV=production
